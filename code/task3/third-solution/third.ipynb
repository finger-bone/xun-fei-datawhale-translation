{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        train_path: str, \n",
    "        dic_path: str,\n",
    "        en_tokenizer: AutoTokenizer,\n",
    "        ch_tokenizer: AutoTokenizer,\n",
    "        truncate: int=384,\n",
    "        pad_multiple: int=8\n",
    "    ):\n",
    "        self.terms = [\n",
    "            {\"en\": l.split(\"\\t\")[0], \"zh\": l.split(\"\\t\")[1]} for l in open(dic_path).read().split(\"\\n\")[:-1]\n",
    "        ]\n",
    "        self.data = [\n",
    "            {\"en\": l.split(\"\\t\")[0], \"zh\": l.split(\"\\t\")[1]} for l in filter(\n",
    "                lambda x: len(x) <= truncate,\n",
    "                open(train_path).read().split(\"\\n\")[:-1]\n",
    "            )\n",
    "        ]\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        self.ch_tokenizer = ch_tokenizer\n",
    "        self.en_tokenizer.add_tokens([\n",
    "            term[\"en\"] for term in self.terms\n",
    "        ])\n",
    "        self.ch_tokenizer.add_tokens([\n",
    "            term[\"zh\"] for term in self.terms\n",
    "        ])\n",
    "        self.pad_multiple = pad_multiple\n",
    "                \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        def pad(x, pad_multiple, pad_token_id=0):\n",
    "            return x + [pad_token_id] * (pad_multiple - len(x) % pad_multiple)\n",
    "        return {\n",
    "            \"en\": pad(self.en_tokenizer.encode(self.data[index][\"en\"]), self.pad_multiple),\n",
    "            \"zh\": pad(self.ch_tokenizer.encode(self.data[index][\"zh\"]), self.pad_multiple),\n",
    "        }\n",
    "    \n",
    "    def get_raw(self, index: int) -> dict:\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fn(batch: dict) -> tuple[Tensor, Tensor]:\n",
    "    # pad the batch\n",
    "    pad_token_id = 0\n",
    "    src = [torch.tensor(item[\"en\"]) for item in batch]\n",
    "    trg = [torch.tensor(item[\"zh\"]) for item in batch]\n",
    "    src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_token_id)\n",
    "    trg = torch.nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=pad_token_id)\n",
    "    return src, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"../../../cache\")\n",
    "ch_tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\", cache_dir=\"../../../cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MTTrainDataset(\n",
    "        \"./data/train.txt\", \n",
    "        \"./data/en-zh.dic\",\n",
    "        en_tokenizer,\n",
    "        ch_tokenizer,\n",
    "    ), \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    collate_fn=collect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_tk, tgt_tk, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "        self.src_embedding = nn.Embedding(len(src_tk), d_model)\n",
    "        self.tgt_embedding = nn.Embedding(len(tgt_tk), d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, len(tgt_tk))\n",
    "        self.src_vocab = src_tk\n",
    "        self.tgt_vocab = tgt_tk\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 调整src和tgt的维度\n",
    "        src = src.transpose(0, 1)  # (seq_len, batch_size)\n",
    "        tgt = tgt.transpose(0, 1)  # (seq_len, batch_size)\n",
    "\n",
    "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(0)).to(src.device)\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(0)).to(tgt.device)\n",
    "\n",
    "        src_padding_mask = (src == 0).transpose(0, 1)\n",
    "        tgt_padding_mask = (tgt == 0).transpose(0, 1)\n",
    "\n",
    "        src_embedded = self.positional_encoding(self.src_embedding(src) * math.sqrt(self.d_model))\n",
    "        tgt_embedded = self.positional_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model))\n",
    "\n",
    "        output = self.transformer(src_embedded, tgt_embedded,\n",
    "                                  src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        return self.fc_out(output).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(src_tk, tgt_tk, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "    model = TransformerModel(src_tk, tgt_tk, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zend/Desktop/xun-fei-datawhale-translation/.pixi/envs/default/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(en_tokenizer, ch_tokenizer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      3\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "epoch_loss = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "    src, tgt = batch\n",
    "    if src.numel() == 0 or tgt.numel() == 0:\n",
    "        continue\n",
    "    \n",
    "    src, tgt = src.to(device), tgt.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt[:, :-1])\n",
    "    \n",
    "    output_dim = output.shape[-1]\n",
    "    output = output.contiguous().view(-1, output_dim)\n",
    "    tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "    \n",
    "    loss = criterion(output, tgt)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
